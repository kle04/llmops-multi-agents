# HÆ°á»›ng dáº«n xá»­ lÃ½ dá»¯ liá»‡u cho LLMOps Multi-Agent System

ThÆ° má»¥c nÃ y chá»©a pipeline xá»­ lÃ½ dá»¯ liá»‡u hoÃ n chá»‰nh Ä‘á»ƒ chuyá»ƒn Ä‘á»•i tÃ i liá»‡u PDF thÃ nh vector embeddings cÃ³ thá»ƒ tÃ¬m kiáº¿m. Pipeline nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho tÃ i liá»‡u sá»©c khá»e tÃ¢m tháº§n tiáº¿ng Viá»‡t.

## ğŸ“‹ Tá»•ng quan Pipeline

Pipeline xá»­ lÃ½ dá»¯ liá»‡u bao gá»“m 3 bÆ°á»›c chÃ­nh:

1. **TrÃ­ch xuáº¥t vÄƒn báº£n** (`01_extract_text.py`) - Chuyá»ƒn Ä‘á»•i PDF thÃ nh vÄƒn báº£n
2. **PhÃ¢n Ä‘oáº¡n vÄƒn báº£n** (`02_chunk_text.py`) - Chia vÄƒn báº£n thÃ nh cÃ¡c chunk cÃ³ kÃ­ch thÆ°á»›c phÃ¹ há»£p
3. **Táº¡o embeddings** (`03_create_embeddings.py`) - Táº¡o vector embeddings vÃ  lÆ°u vÃ o Qdrant

### CÃ i Ä‘áº·t dependencies
```bash
# Tá»« thÆ° má»¥c root cá»§a project
pip install -r src/preprocessing/requirements.txt
```

### Cáº¥u trÃºc dá»¯ liá»‡u Ä‘áº§u vÃ o
Äáº£m báº£o cáº¥u trÃºc thÆ° má»¥c nhÆ° sau:
```
data/
â”œâ”€â”€ raw/                          # PDF files gá»‘c
â”‚   â”œâ”€â”€ document1.pdf
â”‚   â””â”€â”€ document2.pdf
â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ catalog.csv              # Metadata cá»§a documents
â””â”€â”€ processed/
    â”œâ”€â”€ text/                    # Output cá»§a bÆ°á»›c 1
    â”œâ”€â”€ chunks/                  # Output cá»§a bÆ°á»›c 2
    â””â”€â”€ embeddings/              # Output cá»§a bÆ°á»›c 3 (optional)
```

### Cáº¥u trÃºc file catalog.csv
File `data/metadata/catalog.csv` chá»©a cÃ¡c cá»™t sau:
```csv
doc_id,filename,title,source,year,language,audience,grade_range,topics,skip_pages
MOET_001,MOET_SoTay_ThucHanh_CTXH_TrongTruongHoc_vi.pdf,Sá»• tay thá»±c hÃ nh CTXH trong trÆ°á»ng há»c,MOET,2023,vi,teachers,K12,social_work,"1-2,50-52"
```

**CÃ¡c cá»™t báº¯t buá»™c:**
- `doc_id`: ID duy nháº¥t cá»§a tÃ i liá»‡u
- `filename`: TÃªn file PDF trong thÆ° má»¥c `data/raw/`
- `title`: TiÃªu Ä‘á» tÃ i liá»‡u
- `source`: Nguá»“n tÃ i liá»‡u
- `year`: NÄƒm xuáº¥t báº£n
- `language`: NgÃ´n ngá»¯ (máº·c Ä‘á»‹nh: vi)
- `audience`: Äá»‘i tÆ°á»£ng má»¥c tiÃªu
- `grade_range`: Cáº¥p há»c
- `topics`: Chá»§ Ä‘á»
- `skip_pages`: CÃ¡c trang cáº§n bá» qua (format: "1-3,5,8-9")

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

**âš ï¸ LÆ°u Ã½ quan trá»ng:** LuÃ´n cháº¡y cÃ¡c lá»‡nh tá»« thÆ° má»¥c root cá»§a project.

### BÆ°á»›c 1: TrÃ­ch xuáº¥t vÄƒn báº£n tá»« PDF

```bash
python src/preprocessing/01_extract_text.py --catalog data/metadata/catalog.csv --raw_dir data/raw --out_dir data/processed/text --log_level INFO
```

**Tham sá»‘ chÃ­nh:**
- `--catalog`: ÄÆ°á»ng dáº«n Ä‘áº¿n file catalog.csv
- `--raw_dir`: ThÆ° má»¥c chá»©a PDF files
- `--out_dir`: ThÆ° má»¥c output cho vÄƒn báº£n Ä‘Ã£ trÃ­ch xuáº¥t
- `--max_workers`: Sá»‘ worker song song (máº·c Ä‘á»‹nh: 4)
- `--log_level`: Má»©c Ä‘á»™ logging (DEBUG, INFO, WARNING, ERROR)

**Output:**
- `{doc_id}.pages.jsonl`: VÄƒn báº£n theo tá»«ng trang
- `{doc_id}.merged.txt`: VÄƒn báº£n Ä‘Ã£ merge vÃ  lÃ m sáº¡ch

### BÆ°á»›c 2: PhÃ¢n Ä‘oáº¡n vÄƒn báº£n

```bash
python src/preprocessing/02_chunk_text.py --catalog data/metadata/catalog.csv --text_dir data/processed/text --out_dir data/processed/chunks --max_tokens 800 --overlap 120 --min_tokens 120 --auto_toc
```

**Tham sá»‘ chÃ­nh:**
- `--text_dir`: ThÆ° má»¥c chá»©a vÄƒn báº£n Ä‘Ã£ trÃ­ch xuáº¥t
- `--out_dir`: ThÆ° má»¥c output cho chunks
- `--max_tokens`: Sá»‘ token tá»‘i Ä‘a má»—i chunk (máº·c Ä‘á»‹nh: 800)
- `--overlap`: Sá»‘ token overlap giá»¯a cÃ¡c chunk (máº·c Ä‘á»‹nh: 120)
- `--min_tokens`: Sá»‘ token tá»‘i thiá»ƒu má»—i chunk (máº·c Ä‘á»‹nh: 120)
- `--auto_toc`: Tá»± Ä‘á»™ng bá» qua trang má»¥c lá»¥c

**Output:**
- `{doc_id}.jsonl`: Chunks vá»›i metadata Ä‘áº§y Ä‘á»§

### BÆ°á»›c 3: Táº¡o vector embeddings

```bash
python src/preprocessing/03_create_embeddings.py --chunks_dir data/processed/chunks --out_dir data/embeddings --model dangvantuan/vietnamese-embedding --batch_size 8 --qdrant_url http://localhost:6333 --collection_name mental_health_vi
```

**Tham sá»‘ chÃ­nh:**
- `--chunks_dir`: ThÆ° má»¥c chá»©a chunks
- `--out_dir`: ThÆ° má»¥c output cho embeddings (optional)
- `--model`: Model embedding (máº·c Ä‘á»‹nh: dangvantuan/vietnamese-embedding)
- `--batch_size`: Batch size cho encoding (máº·c Ä‘á»‹nh: 8)
- `--device`: Device sá»­ dá»¥ng (auto, cuda, mps, cpu)
- `--qdrant_url`: URL Qdrant server (dÃ¹ng 'none' Ä‘á»ƒ disable)
- `--collection_name`: TÃªn collection trong Qdrant
- `--recreate_collection`: Táº¡o láº¡i collection náº¿u Ä‘Ã£ tá»“n táº¡i

**Output:**
- `{doc_id}.npz`: Vector embeddings (náº¿u --out_dir Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh)
- Dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trá»±c tiáº¿p vÃ o Qdrant database

## ğŸ¯ VÃ­ dá»¥ cháº¡y toÃ n bá»™ pipeline

```bash
# BÆ°á»›c 1: TrÃ­ch xuáº¥t vÄƒn báº£n
python src/preprocessing/01_extract_text.py

# BÆ°á»›c 2: PhÃ¢n Ä‘oáº¡n vÄƒn báº£n
python src/preprocessing/02_chunk_text.py --auto_toc

# BÆ°á»›c 3: Táº¡o embeddings (yÃªu cáº§u Qdrant Ä‘ang cháº¡y)
python src/preprocessing/03_create_embeddings.py
```

## ğŸ› ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t
- **GPU Memory**: Giáº£m `--batch_size` náº¿u gáº·p lá»—i out of memory
- **CPU**: TÄƒng `--max_workers` cho parallel processing
- **Text quality**: Sá»­ dá»¥ng `--auto_toc` Ä‘á»ƒ tá»± Ä‘á»™ng loáº¡i bá» má»¥c lá»¥c

### Cáº¥u hÃ¬nh embedding model
```bash
# Sá»­ dá»¥ng model khÃ¡c
python src/preprocessing/03_create_embeddings.py --model sentence-transformers/all-MiniLM-L6-v2

# Normalize embeddings
python src/preprocessing/03_create_embeddings.py --normalize

# Chá»‰ CPU processing
python src/preprocessing/03_create_embeddings.py --device cpu --max_workers 4
```


## ğŸ“Š Monitoring vÃ  Logging

Táº¥t cáº£ scripts Ä‘á»u há»— trá»£ logging chi tiáº¿t:
- `--log_level DEBUG`: ThÃ´ng tin chi tiáº¿t nháº¥t
- `--log_level INFO`: ThÃ´ng tin cÆ¡ báº£n (máº·c Ä‘á»‹nh)
- `--log_level WARNING`: Chá»‰ cáº£nh bÃ¡o vÃ  lá»—i
- `--log_level ERROR`: Chá»‰ lá»—i

Logs bao gá»“m:
- Sá»‘ lÆ°á»£ng documents/chunks Ä‘Æ°á»£c xá»­ lÃ½
- Thá»i gian xá»­ lÃ½
- Thá»‘ng kÃª hiá»‡u suáº¥t
- Chi tiáº¿t lá»—i vÃ  cÃ¡ch kháº¯c phá»¥c